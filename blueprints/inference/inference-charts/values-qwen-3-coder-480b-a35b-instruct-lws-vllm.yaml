model: Qwen/Qwen3-Coder-480B-A35B-Instruct

modelParameters:
  pipelineParallelSize: 4
  tensorParallelSize: 8

inference:
  serviceName: qwen3-coder-480b-a35b-instruct-lws-vllm
  serviceNamespace: default
  accelerator: gpu
  framework: lws-vllm

  modelServer:
    image:
      repository: vllm/vllm-openai
      tag: v0.10.1
    deployment:
      resources:
        gpu:
          requests:
            nvidia.com/gpu: 8
          limits:
            nvidia.com/gpu: 8
      instanceType: g6e.48xlarge # Highly recommended to add the instance type
