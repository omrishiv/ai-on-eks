<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blueprints/inference/GPUs/nvidia-dynamo" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">NVIDIA Dynamo on Amazon EKS | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="NVIDIA Dynamo on Amazon EKS | AI on EKS"><meta data-rh="true" name="description" content="Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn&#x27;t working, it&#x27;s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren&#x27;t initializing, check the logs for Karpenter or Node groups to resolve the issue."><meta data-rh="true" property="og:description" content="Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn&#x27;t working, it&#x27;s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren&#x27;t initializing, check the logs for Karpenter or Node groups to resolve the issue."><link data-rh="true" rel="icon" href="/ai-on-eks/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo" hreflang="en"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Inference on EKS","item":"https://awslabs.github.io/ai-on-eks/docs/category/inference-on-eks"},{"@type":"ListItem","position":2,"name":"GPU Inference on EKS","item":"https://awslabs.github.io/ai-on-eks/docs/category/gpu-inference-on-eks"},{"@type":"ListItem","position":3,"name":"NVIDIA Dynamo on Amazon EKS","item":"https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo"}]}</script><link rel="stylesheet" href="/ai-on-eks/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/assets/js/runtime~main.612566b1.js" defer="defer"></script>
<script src="/ai-on-eks/assets/js/main.9a602c3f.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now →</a></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/"><div class="navbar__logo"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/infra">Infrastructure</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/docs/blueprints">Blueprints</a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/guidance">Guidance</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/blueprints"><span title="Overview" class="linkLabel_WmDU">Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/docs/category/training-on-eks"><span title="Training on EKS" class="categoryLinkLabel_W154">Training on EKS</span></a><button aria-label="Expand sidebar category &#x27;Training on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai-on-eks/docs/category/inference-on-eks"><span title="Inference on EKS" class="categoryLinkLabel_W154">Inference on EKS</span></a><button aria-label="Collapse sidebar category &#x27;Inference on EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai-on-eks/docs/category/gpu-inference-on-eks"><span title="GPU Inference on EKS" class="categoryLinkLabel_W154">GPU Inference on EKS</span></a><button aria-label="Collapse sidebar category &#x27;GPU Inference on EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/vLLM-rayserve"><span title="RayServe with vLLM" class="linkLabel_WmDU">RayServe with vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/vLLM-NVIDIATritonServer"><span title="NVIDIA Triton Server with vLLM" class="linkLabel_WmDU">NVIDIA Triton Server with vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/stablediffusion-gpus"><span title="Stable Diffusion on GPU" class="linkLabel_WmDU">Stable Diffusion on GPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-nim-llama3"><span title="NVIDIA NIM LLM on Amazon EKS" class="linkLabel_WmDU">NVIDIA NIM LLM on Amazon EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-nim-operator"><span title="NVIDIA NIM Operator on EKS" class="linkLabel_WmDU">NVIDIA NIM Operator on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/ray-vllm-deepseek"><span title="DeepSeek-R1 on EKS" class="linkLabel_WmDU">DeepSeek-R1 on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo"><span title="NVIDIA Dynamo on Amazon EKS" class="linkLabel_WmDU">NVIDIA Dynamo on Amazon EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/aibrix-deepseek-distill"><span title="AIBrix on EKS" class="linkLabel_WmDU">AIBrix on EKS</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai-on-eks/docs/category/neuron-inference-on-eks"><span title="Neuron Inference on EKS" class="categoryLinkLabel_W154">Neuron Inference on EKS</span></a><button aria-label="Expand sidebar category &#x27;Neuron Inference on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference"><span title="Overview" class="linkLabel_WmDU">Overview</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/inference-charts"><span title="Inference Charts" class="linkLabel_WmDU">Inference Charts</span></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai-on-eks/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/docs/category/inference-on-eks"><span>Inference on EKS</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/docs/category/gpu-inference-on-eks"><span>GPU Inference on EKS</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">NVIDIA Dynamo on Amazon EKS</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn&#x27;t working, it&#x27;s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren&#x27;t initializing, check the logs for Karpenter or Node groups to resolve the issue.</p></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>NVIDIA Dynamo is a cloud-native platform for deploying and managing AI inference graphs at scale. This implementation provides complete infrastructure setup with enterprise-grade monitoring and scalability on Amazon EKS.</p></div></div>
<header><h1>NVIDIA Dynamo on Amazon EKS</h1></header>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Active Development</div><div class="admonitionContent_BuS1"><p>This NVIDIA Dynamo blueprint is currently in <strong>active development</strong>. We are continuously improving the user experience and functionality. Features, configurations, and deployment processes may change between releases as we iterate and enhance the implementation based on user feedback and best practices.</p><p>Please expect iterative improvements in upcoming releases. If you encounter any issues or have suggestions for improvements, please feel free to open an issue or contribute to the project.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="quick-start">Quick Start<a href="#quick-start" class="hash-link" aria-label="Direct link to Quick Start" title="Direct link to Quick Start" translate="no">​</a></h2>
<p><strong>Want to get started immediately?</strong> Here&#x27;s the minimal command sequence:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 1. Clone and navigate</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/awslabs/ai-on-eks.git </span><span class="token operator" style="color:#393A34">&amp;&amp;</span><span class="token plain"> </span><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/infra/nvidia-dynamo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 2. Deploy infrastructure and platform (15-30 minutes)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./install.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 3. Deploy inference examples using prebuilt NGC containers</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/blueprints/inference/nvidia-dynamo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./deploy.sh                </span><span class="token comment" style="color:#999988;font-style:italic"># Interactive menu to choose example</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ./deploy.sh vllm           # Deploy vLLM with interactive setup</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 4. Test your deployment (wait for model download)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/vllm-frontend </span><span class="token number" style="color:#36acaa">8000</span><span class="token plain">:8000 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> dynamo-cloud</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> http://localhost:8000/health</span><br></span></code></pre></div></div>
<p><strong>Prerequisites</strong>: AWS CLI, kubectl, helm, terraform, git, NGC API token, HuggingFace token (<a href="#prerequisites">detailed setup below</a>)</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-nvidia-dynamo">What is NVIDIA Dynamo?<a href="#what-is-nvidia-dynamo" class="hash-link" aria-label="Direct link to What is NVIDIA Dynamo?" title="Direct link to What is NVIDIA Dynamo?" translate="no">​</a></h2>
<p><a href="https://github.com/ai-dynamo/dynamo" target="_blank" rel="noopener noreferrer">NVIDIA Dynamo</a> is an open-source inference framework designed to optimize performance and scalability for large language models (LLMs) and generative AI applications. Released under the Apache 2.0 license, Dynamo provides a datacenter-scale distributed inference serving framework that orchestrates complex AI workloads across multiple GPUs and nodes.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-an-inference-graph">What is an Inference Graph?<a href="#what-is-an-inference-graph" class="hash-link" aria-label="Direct link to What is an Inference Graph?" title="Direct link to What is an Inference Graph?" translate="no">​</a></h3>
<p>An <strong>inference graph</strong> is a computational workflow that defines how AI models process data through interconnected nodes, enabling complex multi-step AI operations like:</p>
<ul>
<li><strong>LLM chains</strong>: Sequential processing through multiple language models</li>
<li><strong>Multimodal processing</strong>: Combining text, image, and audio processing</li>
<li><strong>Custom inference pipelines</strong>: Tailored workflows for specific AI applications</li>
<li><strong>Disaggregated serving</strong>: Separating prefill and decode phases for optimal resource utilization</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">​</a></h2>
<p>This blueprint uses the <strong><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/helm-charts/dynamo-platform" target="_blank" rel="noopener noreferrer">official NVIDIA Dynamo Helm charts</a></strong> from the <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo" target="_blank" rel="noopener noreferrer">NVIDIA NGC catalog</a>, with additional shell scripts and Terraform automation to simplify the deployment process on Amazon EKS.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="deployment-approach">Deployment Approach<a href="#deployment-approach" class="hash-link" aria-label="Direct link to Deployment Approach" title="Direct link to Deployment Approach" translate="no">​</a></h3>
<p><strong>Why This Setup Process?</strong>
While this implementation involves multiple steps, it provides several advantages over a simple Helm-only deployment:</p>
<ul>
<li><strong>Complete Infrastructure</strong>: Automatically provisions VPC, EKS cluster, ECR repositories, and monitoring stack</li>
<li><strong>Production Ready</strong>: Includes enterprise-grade security, monitoring, and scalability features</li>
<li><strong>AWS Integration</strong>: Leverages EKS autoscaling, EFA networking, and AWS services</li>
<li><strong>Customizable</strong>: Allows fine-tuning of GPU node pools, networking, and resource allocation</li>
<li><strong>Reproducible</strong>: Infrastructure as Code ensures consistent deployments across environments</li>
</ul>
<p><strong>For Simpler Deployments</strong>: If you already have an EKS cluster and prefer a minimal setup, you can use the Dynamo Helm charts directly from the source repository. This blueprint provides the full production-ready experience.</p>
<p>As LLMs and generative AI applications become increasingly prevalent, the demand for efficient, scalable, and low-latency inference solutions has grown. Traditional inference systems often struggle to meet these demands, especially in distributed, multi-node environments. NVIDIA Dynamo addresses these challenges by offering innovative solutions to optimize performance and scalability with support for AWS services such as Amazon S3, Elastic Fabric Adapter (EFA), and Amazon EKS.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-features">Key Features<a href="#key-features" class="hash-link" aria-label="Direct link to Key Features" title="Direct link to Key Features" translate="no">​</a></h3>
<p><strong>Performance Optimizations:</strong></p>
<ul>
<li><strong>Disaggregated Serving</strong>: Separates prefill and decode phases across different GPUs for optimal resource utilization</li>
<li><strong>Dynamic GPU Scheduling</strong>: Intelligent resource allocation based on real-time demand through the NVIDIA Dynamo Planner</li>
<li><strong>Smart Request Routing</strong>: Minimizes KV cache recomputation by routing requests to workers with relevant cached data</li>
<li><strong>Accelerated Data Transfer</strong>: Low-latency communication via NVIDIA NIXL library</li>
<li><strong>Efficient KV Cache Management</strong>: Intelligent offloading across memory hierarchies with the KV Cache Block Manager</li>
</ul>
<p><strong>Infrastructure Ready:</strong></p>
<ul>
<li><strong>Inference Engine Agnostic</strong>: Supports TensorRT-LLM, vLLM, SGLang, and other runtimes</li>
<li><strong>Modular Design</strong>: Pick and choose components that fit your existing AI stack</li>
<li><strong>Enterprise Grade</strong>: Complete monitoring, logging, and security integration</li>
<li><strong>Amazon EKS Optimized</strong>: Leverages EKS autoscaling, GPU support, and AWS services</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="architecture">Architecture<a href="#architecture" class="hash-link" aria-label="Direct link to Architecture" title="Direct link to Architecture" translate="no">​</a></h2>
<p>The deployment uses Amazon EKS with the following components:</p>
<p><img decoding="async" loading="lazy" src="https://github.com/ai-dynamo/dynamo/blob/main/docs/images/architecture.png?raw=true" alt="NVIDIA Dynamo Architecture" class="img_ev3q"></p>
<p><strong>Key Components:</strong></p>
<ul>
<li><strong>VPC and Networking</strong>: Standard VPC with EFA support for low-latency inter-node communication</li>
<li><strong>EKS Cluster</strong>: Managed Kubernetes with GPU-enabled node groups using Karpenter</li>
<li><strong>Dynamo Platform</strong>: Operator, API Store, and supporting services (NATS, PostgreSQL, MinIO)</li>
<li><strong>Monitoring Stack</strong>: Prometheus, Grafana, and AI/ML observability</li>
<li><strong>Storage</strong>: Amazon EFS for shared model storage and caching</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h2>
<p><strong>System Requirements</strong>: Ubuntu 22.04 or 24.04 (NVIDIA Dynamo officially supports only these versions)</p>
<p>Install the following tools on your setup host (recommended: EC2 instance t3.xlarge or higher with EKS and ECR permissions):</p>
<ul>
<li><strong>AWS CLI</strong>: Configured with appropriate permissions (<a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>kubectl</strong>: Kubernetes command-line tool (<a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>helm</strong>: Kubernetes package manager (<a href="https://helm.sh/docs/intro/install/" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>terraform</strong>: Infrastructure as code tool (<a href="https://learn.hashicorp.com/tutorials/terraform/install-cli" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>git</strong>: Version control (<a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>Python 3.10+</strong>: With pip and venv (<a href="https://www.python.org/downloads/" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>EKS Cluster</strong>: Version 1.33 (tested and supported)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="required-api-tokens">Required API Tokens<a href="#required-api-tokens" class="hash-link" aria-label="Direct link to Required API Tokens" title="Direct link to Required API Tokens" translate="no">​</a></h3>
<ul>
<li><strong><a href="https://catalog.ngc.nvidia.com/" target="_blank" rel="noopener noreferrer">NGC API Token</a></strong>: Required for accessing NVIDIA&#x27;s prebuilt Dynamo container images<!-- -->
<ul>
<li>Sign up at <a href="https://catalog.ngc.nvidia.com/" target="_blank" rel="noopener noreferrer">NVIDIA NGC</a></li>
<li>Generate an API key from your account settings</li>
<li>Set as <code>NGC_API_KEY</code> environment variable or provide during installation</li>
</ul>
</li>
<li><strong><a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">HuggingFace Token</a></strong>: Required for downloading models<!-- -->
<ul>
<li>Create account at <a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">HuggingFace</a></li>
<li>Generate access token with model read permissions</li>
<li>Set as <code>HF_TOKEN</code> environment variable or provide interactively during deployment</li>
</ul>
</li>
</ul>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>Deploying the Solution</span></h2><span class="icon_PckA">👈</span></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="available-examples">Available Examples<a href="#available-examples" class="hash-link" aria-label="Direct link to Available Examples" title="Direct link to Available Examples" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="production-ready-examples">Production-Ready Examples<a href="#production-ready-examples" class="hash-link" aria-label="Direct link to Production-Ready Examples" title="Direct link to Production-Ready Examples" translate="no">​</a></h3>
<p>The following examples are fully tested and production-ready with comprehensive documentation:</p>
<table><thead><tr><th>Example</th><th>Runtime</th><th>Model</th><th>Architecture</th><th>Node Type</th><th>Key Features</th></tr></thead><tbody><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/hello-world" target="_blank" rel="noopener noreferrer">hello-world</a></strong></td><td>CPU</td><td>N/A</td><td>Aggregated</td><td>CPU</td><td>Basic connectivity testing</td></tr><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/vllm" target="_blank" rel="noopener noreferrer">vllm</a></strong></td><td>vLLM</td><td>Qwen3-0.6B</td><td>Aggregated</td><td>G5 GPU</td><td>OpenAI API, balanced performance</td></tr><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/sglang" target="_blank" rel="noopener noreferrer">sglang</a></strong></td><td>SGLang</td><td>DeepSeek-R1-Distill-8B</td><td>Aggregated</td><td>G5 GPU</td><td>RadixAttention caching</td></tr><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/trtllm" target="_blank" rel="noopener noreferrer">trtllm</a></strong></td><td>TensorRT-LLM</td><td>DeepSeek-R1-Distill-8B</td><td>Aggregated</td><td>G5 GPU</td><td>Maximum inference performance</td></tr><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/multi-replica-vllm" target="_blank" rel="noopener noreferrer">multi-replica-vllm</a></strong></td><td>vLLM</td><td>Multiple models</td><td>Multi-replica HA</td><td>G5 GPU</td><td>KV routing, load balancing</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="advanced-examples-beta">Advanced Examples (Beta)<a href="#advanced-examples-beta" class="hash-link" aria-label="Direct link to Advanced Examples (Beta)" title="Direct link to Advanced Examples (Beta)" translate="no">​</a></h3>
<p>These examples demonstrate advanced Dynamo features and are suitable for experimental workloads:</p>
<table><thead><tr><th>Example</th><th>Runtime</th><th>Architecture</th><th>Use Case</th><th>Key Features</th></tr></thead><tbody><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/vllm-disagg" target="_blank" rel="noopener noreferrer">vllm-disagg</a></strong></td><td>vLLM</td><td>Disaggregated</td><td>High throughput</td><td>Separate prefill/decode workers</td></tr><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/sglang-disagg" target="_blank" rel="noopener noreferrer">sglang-disagg</a></strong></td><td>SGLang</td><td>Disaggregated</td><td>Memory optimization</td><td>RadixAttention + disaggregation</td></tr><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/trtllm-disagg" target="_blank" rel="noopener noreferrer">trtllm-disagg</a></strong></td><td>TensorRT-LLM</td><td>Disaggregated</td><td>Ultra-high performance</td><td>TRT-LLM + disaggregation</td></tr><tr><td><strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/kv-routing" target="_blank" rel="noopener noreferrer">kv-routing</a></strong></td><td>Multi-runtime</td><td>Intelligent routing</td><td>Cache optimization</td><td>KV-aware request routing</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-highlights">Example Highlights<a href="#example-highlights" class="hash-link" aria-label="Direct link to Example Highlights" title="Direct link to Example Highlights" translate="no">​</a></h3>
<p><strong>🚀 <strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/hello-world" target="_blank" rel="noopener noreferrer">hello-world</a></strong>: Perfect starting point</strong></p>
<ul>
<li>CPU-only deployment for testing Dynamo platform functionality</li>
<li>Fast deployment (~2 minutes)</li>
<li>No GPU or model dependencies</li>
<li>Ideal for CI/CD validation</li>
</ul>
<p><strong>⚡ <strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/vllm" target="_blank" rel="noopener noreferrer">vllm</a></strong>: Recommended for most use cases</strong></p>
<ul>
<li>OpenAI-compatible API (<code>/v1/chat/completions</code>, <code>/v1/models</code>)</li>
<li>Small model (Qwen3-0.6B) for quick testing</li>
<li>Production-ready health checks</li>
<li>G5 GPU optimization</li>
</ul>
<p><strong>🧠 <strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/sglang" target="_blank" rel="noopener noreferrer">sglang</a></strong>: Advanced caching capabilities</strong></p>
<ul>
<li>RadixAttention for 2-10x speedup on repetitive queries</li>
<li>Structured generation support (JSON/XML)</li>
<li>Advanced memory management</li>
<li>Perfect for cache-heavy workloads</li>
</ul>
<p><strong>🏎️ <strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/trtllm" target="_blank" rel="noopener noreferrer">trtllm</a></strong>: Maximum performance</strong></p>
<ul>
<li>NVIDIA TensorRT-LLM optimized kernels</li>
<li>Highest throughput and lowest latency</li>
<li>Custom CUDA kernels</li>
<li>Best for production serving</li>
</ul>
<p><strong>🌐 <strong><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/multi-replica-vllm" target="_blank" rel="noopener noreferrer">multi-replica-vllm</a></strong>: High availability deployments</strong></p>
<ul>
<li>Multiple independent worker replicas with KV routing</li>
<li>Automatic load balancing and failover</li>
<li>Intelligent cache-aware request routing</li>
<li>Ideal for production workloads requiring high availability</li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Comprehensive Testing</div><div class="admonitionContent_BuS1"><p>All 9 examples have been thoroughly tested and validated with on EKS clusters with GPU nodes. Each example includes proper health checks, OpenAI-compatible API endpoints, and production-ready configurations. See our <a href="https://github.com/awslabs/ai-on-eks/blob/main/NVIDIA_Dynamo_Testing_Summary.md" target="_blank" rel="noopener noreferrer">testing summary</a> for detailed validation results.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="test-and-validate">Test and Validate<a href="#test-and-validate" class="hash-link" aria-label="Direct link to Test and Validate" title="Direct link to Test and Validate" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="automated-testing">Automated Testing<a href="#automated-testing" class="hash-link" aria-label="Direct link to Automated Testing" title="Direct link to Automated Testing" translate="no">​</a></h3>
<p>Use the built-in test script to validate your deployment:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./test.sh</span><br></span></code></pre></div></div>
<p>This script:</p>
<ul>
<li>Starts port forwarding to the frontend service</li>
<li>Tests health check, metrics, and <code>/v1/models</code> endpoints</li>
<li>Runs sample inference requests to verify functionality</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="manual-testing">Manual Testing<a href="#manual-testing" class="hash-link" aria-label="Direct link to Manual Testing" title="Direct link to Manual Testing" translate="no">​</a></h3>
<p>Access your deployment directly:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">frontend-service</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8000</span><span class="token plain">:8000 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> dynamo-cloud </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://localhost:8000/v1/chat/completions </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Explain what a Q-Bit is in quantum computing.&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;max_tokens&quot;: 2000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;temperature&quot;: 0.7,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;stream&quot;: false</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">}&#x27;</span><br></span></code></pre></div></div>
<p><strong>Expected Output:</strong></p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;id&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;1918b11a-6d98-4891-bc84-08f99de70fd0&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;choices&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">&quot;index&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">&quot;message&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">&quot;content&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;A Q-bit, or qubit, is the basic unit of quantum information...&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">&quot;role&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;assistant&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">&quot;finish_reason&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;stop&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;created&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1752018267</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;model&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;object&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;chat.completion&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="monitor-and-observe">Monitor and Observe<a href="#monitor-and-observe" class="hash-link" aria-label="Direct link to Monitor and Observe" title="Direct link to Monitor and Observe" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="grafana-dashboard">Grafana Dashboard<a href="#grafana-dashboard" class="hash-link" aria-label="Direct link to Grafana Dashboard" title="Direct link to Grafana Dashboard" translate="no">​</a></h3>
<p>Access Grafana for visualization (default port 3000):</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> kube-prometheus-stack svc/kube-prometheus-stack-grafana </span><span class="token number" style="color:#36acaa">3000</span><span class="token plain">:80</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prometheus-metrics">Prometheus Metrics<a href="#prometheus-metrics" class="hash-link" aria-label="Direct link to Prometheus Metrics" title="Direct link to Prometheus Metrics" translate="no">​</a></h3>
<p>Access Prometheus for metrics collection (port 9090):</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> kube-prometheus-stack svc/prometheus </span><span class="token number" style="color:#36acaa">9090</span><span class="token plain">:80</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="automatic-monitoring">Automatic Monitoring<a href="#automatic-monitoring" class="hash-link" aria-label="Direct link to Automatic Monitoring" title="Direct link to Automatic Monitoring" translate="no">​</a></h3>
<p>The deployment automatically creates:</p>
<ul>
<li><strong>Service</strong>: Exposes inference graphs for API calls and metrics</li>
<li><strong>ServiceMonitor</strong>: Configures Prometheus to scrape metrics</li>
<li><strong>Dashboards</strong>: Pre-configured Grafana dashboards for inference monitoring</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="advanced-configuration">Advanced Configuration<a href="#advanced-configuration" class="hash-link" aria-label="Direct link to Advanced Configuration" title="Direct link to Advanced Configuration" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="version-management">Version Management<a href="#version-management" class="hash-link" aria-label="Direct link to Version Management" title="Direct link to Version Management" translate="no">​</a></h3>
<p>The deployment automatically manages Dynamo versions with flexible override options:</p>
<p><strong>Default Behavior:</strong></p>
<ul>
<li>Reads version from <code>terraform/blueprint.tfvars</code> (<code>dynamo_stack_version = &quot;v0.4.1&quot;</code>)</li>
<li>Automatically updates container image tags in YAML manifests</li>
<li>Creates temporary manifests without modifying source files</li>
</ul>
<p><strong>Override Options:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Environment variable (highest priority)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">DYNAMO_VERSION</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">v0.4.1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./deploy.sh vllm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Inline override</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token assign-left variable" style="color:#36acaa">DYNAMO_VERSION</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">v0.4.1 ./deploy.sh sglang</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Update terraform/blueprint.tfvars (persistent)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dynamo_stack_version </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;v0.4.1&quot;</span><br></span></code></pre></div></div>
<p><strong>Supported Versions:</strong></p>
<ul>
<li><strong>v0.4.1</strong>: Current stable release (default)</li>
<li>Custom versions from private builds</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="custom-model-deployment">Custom Model Deployment<a href="#custom-model-deployment" class="hash-link" aria-label="Direct link to Custom Model Deployment" title="Direct link to Custom Model Deployment" translate="no">​</a></h3>
<p>To deploy custom models, modify the configuration files in <code>dynamo/examples/llm/configs/</code>:</p>
<ol>
<li><strong>Choose Architecture</strong>: Select based on model size and requirements</li>
<li><strong>Update Configuration</strong>: Edit the appropriate YAML file</li>
<li><strong>Set Model Parameters</strong>: Update <code>model</code> and <code>served_model_name</code> fields</li>
<li><strong>Configure Resources</strong>: Adjust GPU allocation and memory settings</li>
</ol>
<p><strong>Example for DeepSeek-R1 70B model:</strong></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">Common</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> deepseek</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">ai/DeepSeek</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">R1</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">Distill</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">Llama</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">70B</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">max-model-len</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32768</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tensor-parallel-size</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">Frontend</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">served_model_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> deepseek</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">ai/DeepSeek</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">R1</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">Distill</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">Llama</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">70B</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">VllmWorker</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">ServiceArgs</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">gpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;4&#x27;</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="configuration-options">Configuration Options<a href="#configuration-options" class="hash-link" aria-label="Direct link to Configuration Options" title="Direct link to Configuration Options" translate="no">​</a></h3>
<p>The main configuration is in <code>terraform/blueprint.tfvars</code>:</p>
<div class="language-hcl codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-hcl codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Required for Dynamo deployment</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token property" style="color:#36acaa">enable_dynamo_stack</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token property" style="color:#36acaa">enable_argocd</span><span class="token plain">       </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Dynamo platform version</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token property" style="color:#36acaa">dynamo_stack_version</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;v0.4.1&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Required infrastructure components</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token property" style="color:#36acaa">enable_aws_efs_csi_driver</span><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token property" style="color:#36acaa">enable_aws_efa_k8s_device_plugin</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token property" style="color:#36acaa">enable_ai_ml_observability_stack</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="troubleshooting">Troubleshooting<a href="#troubleshooting" class="hash-link" aria-label="Direct link to Troubleshooting" title="Direct link to Troubleshooting" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="common-issues">Common Issues<a href="#common-issues" class="hash-link" aria-label="Direct link to Common Issues" title="Direct link to Common Issues" translate="no">​</a></h3>
<ol>
<li><strong>GPU Nodes Not Available</strong>: Check Karpenter logs and instance availability</li>
<li><strong>Pod Failures</strong>: Check resource limits and cluster capacity</li>
<li><strong>Model Download Failures</strong>: Verify HuggingFace token and network connectivity</li>
<li><strong>API 503 Errors</strong>: Wait for model loading or check worker health</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="debug-commands">Debug Commands<a href="#debug-commands" class="hash-link" aria-label="Direct link to Debug Commands" title="Direct link to Debug Commands" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Check cluster status</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get nodes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> dynamo-cloud</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># View logs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> argocd </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> app.kubernetes.io/name</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">argocd-server</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> dynamo-cloud </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">app</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">vllm-worker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Check deployments</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get dynamographdeployment </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> dynamo-cloud</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl describe dynamographdeployment </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">name</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> dynamo-cloud</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="node-selection-and-customization">Node Selection and Customization<a href="#node-selection-and-customization" class="hash-link" aria-label="Direct link to Node Selection and Customization" title="Direct link to Node Selection and Customization" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="selecting-instance-types">Selecting Instance Types<a href="#selecting-instance-types" class="hash-link" aria-label="Direct link to Selecting Instance Types" title="Direct link to Selecting Instance Types" translate="no">​</a></h3>
<p>You can customize which Karpenter node pool your Dynamo components deploy to by modifying the <code>nodeSelector</code> in your DynamoGraphDeployment:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Example: Deploy GPU worker to G5 instances</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">VllmWorker</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">extraPodSpec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">karpenter.sh/nodepool</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g5</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">karpenter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">gpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;1&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Example: Deploy frontend to CPU instances</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">Frontend</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">extraPodSpec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">karpenter.sh/nodepool</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> cpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">karpenter</span><br></span></code></pre></div></div>
<p><strong>Available Node Pools</strong> (configured in base infrastructure):</p>
<ul>
<li><code>g5-gpu-karpenter</code>: G5 instances with NVIDIA A10G GPUs</li>
<li><code>g6-gpu-karpenter</code>: G6 instances with NVIDIA L4 GPUs (if configured)</li>
<li><code>cpu-karpenter</code>: CPU-only instances for frontends</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="custom-development">Custom Development<a href="#custom-development" class="hash-link" aria-label="Direct link to Custom Development" title="Direct link to Custom Development" translate="no">​</a></h3>
<p>For advanced customization and development:</p>
<ol>
<li><strong>Source Code</strong>: Full Dynamo source code is available at <a href="https://github.com/ai-dynamo/dynamo" target="_blank" rel="noopener noreferrer">~/dynamo</a> with comprehensive documentation and examples</li>
<li><strong>Blueprint Examples</strong>: Each example in the <code>blueprints/inference/nvidia-dynamo/</code> folder includes detailed README files</li>
<li><strong>Container Source</strong>: All source code is included in NGC containers at <code>/workspace/</code> for in-container customization</li>
</ol>
<p>Refer to the individual README files in each blueprint example for specific customization guidance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-node-tensor-parallelism-limitations">Multi-Node Tensor Parallelism Limitations<a href="#multi-node-tensor-parallelism-limitations" class="hash-link" aria-label="Direct link to Multi-Node Tensor Parallelism Limitations" title="Direct link to Multi-Node Tensor Parallelism Limitations" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-multi-replica-vs-multi-node">Understanding Multi-Replica vs Multi-Node<a href="#understanding-multi-replica-vs-multi-node" class="hash-link" aria-label="Direct link to Understanding Multi-Replica vs Multi-Node" title="Direct link to Understanding Multi-Replica vs Multi-Node" translate="no">​</a></h3>
<p>It&#x27;s important to distinguish between <strong>multi-replica deployments</strong> (what our examples provide) and <strong>true multi-node tensor parallelism</strong> (which requires specialized infrastructure):</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="what-our-examples-provide-multi-replica">What Our Examples Provide (Multi-Replica)<a href="#what-our-examples-provide-multi-replica" class="hash-link" aria-label="Direct link to What Our Examples Provide (Multi-Replica)" title="Direct link to What Our Examples Provide (Multi-Replica)" translate="no">​</a></h4>
<ul>
<li><strong>Multiple Independent Workers</strong>: Each worker replica runs the complete model independently (TP=1)</li>
<li><strong>High Availability</strong>: Service continues operating if individual workers fail</li>
<li><strong>Load Balancing</strong>: Requests distributed across workers for increased throughput</li>
<li><strong>KV-Aware Routing</strong>: Intelligent request routing based on cache overlap to maximize performance</li>
<li><strong>Kubernetes Native</strong>: Works seamlessly with standard Kubernetes deployments</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="what-our-examples-do-not-provide-true-multi-node-tp">What Our Examples Do NOT Provide (True Multi-Node TP)<a href="#what-our-examples-do-not-provide-true-multi-node-tp" class="hash-link" aria-label="Direct link to What Our Examples Do NOT Provide (True Multi-Node TP)" title="Direct link to What Our Examples Do NOT Provide (True Multi-Node TP)" translate="no">​</a></h4>
<ul>
<li><strong>Cross-Node Model Sharding</strong>: Models are not split across multiple nodes</li>
<li><strong>Memory Scaling for Large Models</strong>: Each worker must fit the complete model (no cross-node memory sharing)</li>
<li><strong>Tensor Parallelism Across Nodes</strong>: No cross-node tensor operations</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="current-kubernetes-limitations">Current Kubernetes Limitations<a href="#current-kubernetes-limitations" class="hash-link" aria-label="Direct link to Current Kubernetes Limitations" title="Direct link to Current Kubernetes Limitations" translate="no">​</a></h3>
<p><strong>Kubernetes does not currently support true multi-node tensor parallelism</strong> for distributed inference workloads due to several technical constraints:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="infrastructure-requirements">Infrastructure Requirements<a href="#infrastructure-requirements" class="hash-link" aria-label="Direct link to Infrastructure Requirements" title="Direct link to Infrastructure Requirements" translate="no">​</a></h4>
<p>True multi-node tensor parallelism requires:</p>
<ul>
<li><strong>MPI/Slurm Environment</strong>: Uses <code>mpirun</code> or <code>srun</code> for coordinated distributed model loading</li>
<li><strong>Synchronized Initialization</strong>: All participating nodes must start simultaneously and maintain coordination</li>
<li><strong>Low-Latency Interconnects</strong>: Requires InfiniBand, NVLink, or similar high-performance networking</li>
<li><strong>Shared Process Groups</strong>: Distributed training/inference frameworks need process group management not available in K8s</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="why-kubernetes-doesnt-support-this-currently">Why Kubernetes Doesn&#x27;t Support This (Currently)<a href="#why-kubernetes-doesnt-support-this-currently" class="hash-link" aria-label="Direct link to Why Kubernetes Doesn&#x27;t Support This (Currently)" title="Direct link to Why Kubernetes Doesn&#x27;t Support This (Currently)" translate="no">​</a></h4>
<ol>
<li><strong>Pod Isolation</strong>: Kubernetes pods are designed to be isolated units, making cross-pod tensor operations challenging</li>
<li><strong>Dynamic Scheduling</strong>: K8s dynamic pod placement conflicts with the static, coordinated startup required for multi-node TP</li>
<li><strong>Network Abstraction</strong>: K8s networking abstractions don&#x27;t expose the low-level network primitives needed for efficient tensor communication</li>
<li><strong>Missing MPI Integration</strong>: No native MPI job management in Kubernetes (though projects like MPI-Operator exist, they&#x27;re not widely adopted for inference)</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="current-support-in-dynamo-backends">Current Support in Dynamo Backends<a href="#current-support-in-dynamo-backends" class="hash-link" aria-label="Direct link to Current Support in Dynamo Backends" title="Direct link to Current Support in Dynamo Backends" translate="no">​</a></h3>
<p>Based on the official Dynamo documentation and examples, here&#x27;s what each backend supports:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="sglang-multi-node-support-">SGLang Multi-Node Support ✅<a href="#sglang-multi-node-support-" class="hash-link" aria-label="Direct link to SGLang Multi-Node Support ✅" title="Direct link to SGLang Multi-Node Support ✅" translate="no">​</a></h4>
<ul>
<li><strong>Status</strong>: Fully supported for multi-node tensor parallelism</li>
<li><strong>Requirements</strong>: Slurm environment with MPI coordination</li>
<li><strong>Configuration</strong>: Uses <code>--nnodes</code>, <code>--node-rank</code>, and <code>--dist-init-addr</code> parameters</li>
<li><strong>Example</strong>: DeepSeek-R1 across 4 nodes with TP16 (16 GPUs total)</li>
<li><strong>Kubernetes</strong>: Not supported - requires Slurm/MPI environment</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># SGLang multi-node example (Slurm only)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> dynamo.sglang.worker </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --model-path /model/ </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--tp</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">16</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--nnodes</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --node-rank </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --dist-init-addr </span><span class="token variable" style="color:#36acaa">${HEAD_NODE_IP}</span><span class="token plain">:29500</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="tensorrt-llm-multi-node-support-">TensorRT-LLM Multi-Node Support ✅<a href="#tensorrt-llm-multi-node-support-" class="hash-link" aria-label="Direct link to TensorRT-LLM Multi-Node Support ✅" title="Direct link to TensorRT-LLM Multi-Node Support ✅" translate="no">​</a></h4>
<ul>
<li><strong>Status</strong>: Fully supported with WideEP (Wide Expert Parallelism)</li>
<li><strong>Requirements</strong>: Slurm environment with MPI launcher (<code>srun</code> or <code>mpirun</code>)</li>
<li><strong>Configuration</strong>: Multi-node TP16/EP16 configurations available</li>
<li><strong>Example</strong>: DeepSeek-R1 across 4x GB200 nodes</li>
<li><strong>Kubernetes</strong>: Not supported - requires MPI coordination</li>
</ul>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># TRT-LLM multi-node example (Slurm only)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">srun </span><span class="token parameter variable" style="color:#36acaa">--nodes</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">4</span><span class="token plain"> --ntasks-per-node</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">4</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> dynamo.trtllm </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --model-path /model/ </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --engine-config wide_ep_config.yaml</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="vllm-multi-node-support-">vLLM Multi-Node Support ❌<a href="#vllm-multi-node-support-" class="hash-link" aria-label="Direct link to vLLM Multi-Node Support ❌" title="Direct link to vLLM Multi-Node Support ❌" translate="no">​</a></h4>
<ul>
<li><strong>Status</strong>: Currently not supported for true multi-node tensor parallelism</li>
<li><strong>Current Capability</strong>: Single-node tensor parallelism only (multiple GPUs on same node)</li>
<li><strong>Our Implementation</strong>: Multi-replica for high availability (each replica runs full model)</li>
<li><strong>Future</strong>: May be added in future vLLM releases</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="workarounds-for-large-models">Workarounds for Large Models<a href="#workarounds-for-large-models" class="hash-link" aria-label="Direct link to Workarounds for Large Models" title="Direct link to Workarounds for Large Models" translate="no">​</a></h3>
<p>If you need to run models that don&#x27;t fit on a single node, consider these alternatives:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-high-memory-single-node-instances">1. High-Memory Single-Node Instances<a href="#1-high-memory-single-node-instances" class="hash-link" aria-label="Direct link to 1. High-Memory Single-Node Instances" title="Direct link to 1. High-Memory Single-Node Instances" translate="no">​</a></h4>
<p>Use AWS instances with large GPU memory:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Example: P5.48xlarge with 8x H100 (80GB each = 640GB total)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">extraPodSpec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">karpenter.sh/nodepool</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> p5</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">karpenter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">node.kubernetes.io/instance-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> p5.48xlarge</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">gpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;8&quot;</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-model-optimization-techniques">2. Model Optimization Techniques<a href="#2-model-optimization-techniques" class="hash-link" aria-label="Direct link to 2. Model Optimization Techniques" title="Direct link to 2. Model Optimization Techniques" translate="no">​</a></h4>
<ul>
<li><strong>Quantization</strong>: Use FP16, FP8, or INT8 quantized models</li>
<li><strong>Model Pruning</strong>: Remove less important parameters</li>
<li><strong>LoRA/QLoRA</strong>: Use parameter-efficient fine-tuned models</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-slurm-based-deployments">3. Slurm-Based Deployments<a href="#3-slurm-based-deployments" class="hash-link" aria-label="Direct link to 3. Slurm-Based Deployments" title="Direct link to 3. Slurm-Based Deployments" translate="no">​</a></h4>
<p>For models requiring true multi-node TP, deploy outside Kubernetes:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Use official Dynamo examples with Slurm</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> ~/dynamo/docs/components/backends/trtllm/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./srun_disaggregated.sh  </span><span class="token comment" style="color:#999988;font-style:italic"># 8-node disaggregated deployment</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-disaggregated-architecture">4. Disaggregated Architecture<a href="#4-disaggregated-architecture" class="hash-link" aria-label="Direct link to 4. Disaggregated Architecture" title="Direct link to 4. Disaggregated Architecture" translate="no">​</a></h4>
<p>Use our disaggregated examples for better resource utilization:</p>
<ul>
<li><strong>Prefill Workers</strong>: Handle input processing (can be smaller instances)</li>
<li><strong>Decode Workers</strong>: Handle token generation (optimized for throughput)</li>
<li><strong>Independent Scaling</strong>: Scale each component based on workload</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="future-development">Future Development<a href="#future-development" class="hash-link" aria-label="Direct link to Future Development" title="Direct link to Future Development" translate="no">​</a></h3>
<p><strong>Multi-Node Tensor Parallelism in Kubernetes</strong> may become available in future versions through:</p>
<ol>
<li><strong>Enhanced MPI Integration</strong>: Projects like Kubeflow&#x27;s MPI-Operator for inference workloads</li>
<li><strong>Native K8s Support</strong>: Kubernetes SIG-Scheduling working on gang scheduling and coordinated pod startup</li>
<li><strong>Vendor Solutions</strong>: Cloud providers may develop custom solutions for managed inference</li>
<li><strong>Framework Evolution</strong>: Inference frameworks adding Kubernetes-native distributed execution</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="recommendations">Recommendations<a href="#recommendations" class="hash-link" aria-label="Direct link to Recommendations" title="Direct link to Recommendations" translate="no">​</a></h3>
<p><strong>For Current Deployments:</strong></p>
<ol>
<li><strong>Small to Medium Models (≤70B)</strong>: Use single-node deployments with multi-GPU instances</li>
<li><strong>High Availability Needs</strong>: Use our multi-replica examples with KV routing</li>
<li><strong>Large Models (70B+)</strong>: Consider Slurm-based deployments outside Kubernetes</li>
<li><strong>Maximum Performance</strong>: Use disaggregated architecture with optimized worker ratios</li>
</ol>
<p><strong>Monitoring Future Developments:</strong></p>
<ul>
<li>Follow <a href="https://github.com/ai-dynamo/dynamo/releases" target="_blank" rel="noopener noreferrer">Dynamo releases</a> for Kubernetes multi-node TP updates</li>
<li>Check <a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener noreferrer">TensorRT-LLM</a> and <a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM</a> roadmaps</li>
<li>Monitor <a href="https://github.com/kubernetes/community/tree/master/sig-scheduling" target="_blank" rel="noopener noreferrer">Kubernetes SIG-Scheduling</a> for gang scheduling improvements</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="alternative-deployment-options">Alternative Deployment Options<a href="#alternative-deployment-options" class="hash-link" aria-label="Direct link to Alternative Deployment Options" title="Direct link to Alternative Deployment Options" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="for-existing-eks-clusters">For Existing EKS Clusters<a href="#for-existing-eks-clusters" class="hash-link" aria-label="Direct link to For Existing EKS Clusters" title="Direct link to For Existing EKS Clusters" translate="no">​</a></h3>
<p>If you already have an EKS cluster with GPU nodes and prefer a simpler approach:</p>
<ol>
<li><strong>Direct Helm Installation</strong>: Use the official NVIDIA Dynamo Helm charts directly from the <a href="https://github.com/ai-dynamo/dynamo" target="_blank" rel="noopener noreferrer">dynamo source repository</a></li>
<li><strong>Manual Setup</strong>: Follow the upstream NVIDIA Dynamo documentation for Kubernetes deployment</li>
<li><strong>Custom Integration</strong>: Integrate Dynamo components into your existing infrastructure</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-use-this-blueprint">Why Use This Blueprint?<a href="#why-use-this-blueprint" class="hash-link" aria-label="Direct link to Why Use This Blueprint?" title="Direct link to Why Use This Blueprint?" translate="no">​</a></h3>
<p>This blueprint is designed for users who want:</p>
<ul>
<li><strong>Complete Infrastructure</strong>: End-to-end setup from VPC to running inference</li>
<li><strong>Production Readiness</strong>: Enterprise-grade monitoring, security, and scalability</li>
<li><strong>AWS Integration</strong>: Optimized for EKS, ECR, EFA, and other AWS services</li>
<li><strong>Best Practices</strong>: Follows ai-on-eks patterns and AWS recommendations</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="official-nvidia-resources">Official NVIDIA Resources<a href="#official-nvidia-resources" class="hash-link" aria-label="Direct link to Official NVIDIA Resources" title="Direct link to Official NVIDIA Resources" translate="no">​</a></h3>
<p><strong>📚 Documentation:</strong></p>
<ul>
<li><a href="https://docs.nvidia.com/dynamo/latest/" target="_blank" rel="noopener noreferrer">NVIDIA Dynamo Official Docs</a>: Complete platform documentation</li>
<li><a href="https://developer.nvidia.com/blog/introducing-nvidia-dynamo-a-low-latency-distributed-inference-framework-for-scaling-reasoning-ai-models/" target="_blank" rel="noopener noreferrer">NVIDIA Developer Blog</a>: Introduction and architecture overview</li>
<li><a href="https://developer.nvidia.com/dynamo" target="_blank" rel="noopener noreferrer">NVIDIA Dynamo Product Page</a>: Official product information</li>
</ul>
<p><strong>🐙 Source Code:</strong></p>
<ul>
<li><a href="https://github.com/ai-dynamo/dynamo" target="_blank" rel="noopener noreferrer">NVIDIA Dynamo GitHub</a>: Main repository with source code</li>
<li><a href="https://github.com/ai-dynamo/nixl" target="_blank" rel="noopener noreferrer">NVIDIA NIXL Library</a>: NVIDIA Inference Xfer Library for low-latency communication</li>
</ul>
<p><strong>📦 Container Images &amp; Helm Charts:</strong></p>
<ul>
<li><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo" target="_blank" rel="noopener noreferrer">Dynamo Collection (NGC)</a>: Complete collection of Dynamo resources</li>
<li><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/helm-charts/dynamo-platform" target="_blank" rel="noopener noreferrer">Dynamo Platform Helm Chart</a>: Official Kubernetes deployment</li>
<li><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/containers/vllm-runtime" target="_blank" rel="noopener noreferrer">vLLM Runtime Container</a>: vLLM backend (v0.4.1)</li>
<li><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/containers/sglang-runtime" target="_blank" rel="noopener noreferrer">SGLang Runtime Container</a>: SGLang backend (v0.4.1)</li>
<li><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/containers/trtllm-runtime" target="_blank" rel="noopener noreferrer">TensorRT-LLM Runtime Container</a>: TRT-LLM backend (v0.4.1)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-on-eks-blueprint-resources">AI-on-EKS Blueprint Resources<a href="#ai-on-eks-blueprint-resources" class="hash-link" aria-label="Direct link to AI-on-EKS Blueprint Resources" title="Direct link to AI-on-EKS Blueprint Resources" translate="no">​</a></h3>
<p><strong>🏗️ Infrastructure &amp; Examples:</strong></p>
<ul>
<li><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer">AI-on-EKS Repository</a>: Main blueprint repository</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo" target="_blank" rel="noopener noreferrer">Dynamo Blueprint</a>: Complete blueprint with examples</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/infra/nvidia-dynamo" target="_blank" rel="noopener noreferrer">Infrastructure Code</a>: Terraform and deployment scripts</li>
</ul>
<p><strong>📖 Example Documentation:</strong></p>
<ul>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/hello-world/README.md" target="_blank" rel="noopener noreferrer">Hello World</a>: CPU-only testing example</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/vllm/README.md" target="_blank" rel="noopener noreferrer">vLLM Example</a>: vLLM aggregated serving</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/sglang/README.md" target="_blank" rel="noopener noreferrer">SGLang Example</a>: RadixAttention caching</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/trtllm/README.md" target="_blank" rel="noopener noreferrer">TensorRT-LLM Example</a>: Optimized inference</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo/multi-replica-vllm/README.md" target="_blank" rel="noopener noreferrer">Multi-Replica vLLM</a>: High availability deployments</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="related-technologies">Related Technologies<a href="#related-technologies" class="hash-link" aria-label="Direct link to Related Technologies" title="Direct link to Related Technologies" translate="no">​</a></h3>
<p><strong>🚀 Inference Frameworks:</strong></p>
<ul>
<li><a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM</a>: High-throughput LLM inference engine</li>
<li><a href="https://github.com/sgl-project/sglang" target="_blank" rel="noopener noreferrer">SGLang</a>: Structured generation with RadixAttention</li>
<li><a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener noreferrer">TensorRT-LLM</a>: NVIDIA&#x27;s optimized inference library</li>
</ul>
<p><strong>☸️ Kubernetes &amp; AWS:</strong></p>
<ul>
<li><a href="https://aws.amazon.com/eks/" target="_blank" rel="noopener noreferrer">Amazon EKS</a>: Managed Kubernetes service</li>
<li><a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a>: Kubernetes node autoscaling</li>
<li><a href="https://argo-cd.readthedocs.io/" target="_blank" rel="noopener noreferrer">ArgoCD</a>: GitOps continuous delivery</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">​</a></h2>
<ol>
<li><strong>Explore Examples</strong>: Check the examples folder in the GitHub repository</li>
<li><strong>Scale Deployments</strong>: Configure multi-node setups for larger models</li>
<li><strong>Integrate Applications</strong>: Connect your applications to the inference endpoints</li>
<li><strong>Monitor Performance</strong>: Use Grafana dashboards for ongoing monitoring</li>
<li><strong>Optimize Costs</strong>: Implement auto-scaling and resource optimization</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="clean-up">Clean Up<a href="#clean-up" class="hash-link" aria-label="Direct link to Clean Up" title="Direct link to Clean Up" translate="no">​</a></h2>
<p>When you&#x27;re finished with your NVIDIA Dynamo deployment, remove all resources using the consolidated cleanup script:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> infra/nvidia-dynamo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./cleanup.sh</span><br></span></code></pre></div></div>
<p><strong>What gets cleaned up (in proper order):</strong></p>
<ul>
<li><strong>Dynamo Examples</strong>: All deployed inference graphs and workloads</li>
<li><strong>Dynamo Platform</strong>: Operator, API Store, and supporting services</li>
<li><strong>ArgoCD Applications</strong>: GitOps-managed resources</li>
<li><strong>Kubernetes Resources</strong>: Namespaces, secrets, and configurations</li>
<li><strong>Infrastructure</strong>: EKS cluster, VPC, security groups, and all AWS resources</li>
<li><strong>Cost Optimization</strong>: Ensures no lingering resources continue billing</li>
</ul>
<p><strong>Features:</strong></p>
<ul>
<li><strong>Intelligent Ordering</strong>: Cleans up dependencies in correct sequence</li>
<li><strong>Safety Checks</strong>: Confirms resource existence before deletion attempts</li>
<li><strong>Progress Feedback</strong>: Shows cleanup progress and any issues encountered</li>
<li><strong>Complete Removal</strong>: No manual cleanup steps required</li>
</ul>
<p><strong>Duration</strong>: ~10-15 minutes for complete infrastructure teardown</p>
<p>This deployment provides a production-ready NVIDIA Dynamo environment on Amazon EKS with enterprise-grade features including Karpenter automatic scaling, EFA networking, and seamless AWS service integration.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/inference/GPUs/nvidia-dynamo.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/docs/blueprints/inference/GPUs/ray-vllm-deepseek"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">DeepSeek-R1 on EKS</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/docs/blueprints/inference/GPUs/aibrix-deepseek-distill"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">AIBrix on EKS</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#quick-start" class="table-of-contents__link toc-highlight">Quick Start</a></li><li><a href="#what-is-nvidia-dynamo" class="table-of-contents__link toc-highlight">What is NVIDIA Dynamo?</a><ul><li><a href="#what-is-an-inference-graph" class="table-of-contents__link toc-highlight">What is an Inference Graph?</a></li></ul></li><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a><ul><li><a href="#deployment-approach" class="table-of-contents__link toc-highlight">Deployment Approach</a></li><li><a href="#key-features" class="table-of-contents__link toc-highlight">Key Features</a></li></ul></li><li><a href="#architecture" class="table-of-contents__link toc-highlight">Architecture</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a><ul><li><a href="#required-api-tokens" class="table-of-contents__link toc-highlight">Required API Tokens</a></li><li><a href="#step-1-clone-the-repository" class="table-of-contents__link toc-highlight">Step 1: Clone the Repository</a></li><li><a href="#step-2-deploy-infrastructure-and-platform" class="table-of-contents__link toc-highlight">Step 2: Deploy Infrastructure and Platform</a></li><li><a href="#step-3-deploy-inference-examples" class="table-of-contents__link toc-highlight">Step 3: Deploy Inference Examples</a></li></ul></li><li><a href="#available-examples" class="table-of-contents__link toc-highlight">Available Examples</a><ul><li><a href="#production-ready-examples" class="table-of-contents__link toc-highlight">Production-Ready Examples</a></li><li><a href="#advanced-examples-beta" class="table-of-contents__link toc-highlight">Advanced Examples (Beta)</a></li><li><a href="#example-highlights" class="table-of-contents__link toc-highlight">Example Highlights</a></li></ul></li><li><a href="#test-and-validate" class="table-of-contents__link toc-highlight">Test and Validate</a><ul><li><a href="#automated-testing" class="table-of-contents__link toc-highlight">Automated Testing</a></li><li><a href="#manual-testing" class="table-of-contents__link toc-highlight">Manual Testing</a></li></ul></li><li><a href="#monitor-and-observe" class="table-of-contents__link toc-highlight">Monitor and Observe</a><ul><li><a href="#grafana-dashboard" class="table-of-contents__link toc-highlight">Grafana Dashboard</a></li><li><a href="#prometheus-metrics" class="table-of-contents__link toc-highlight">Prometheus Metrics</a></li><li><a href="#automatic-monitoring" class="table-of-contents__link toc-highlight">Automatic Monitoring</a></li></ul></li><li><a href="#advanced-configuration" class="table-of-contents__link toc-highlight">Advanced Configuration</a><ul><li><a href="#version-management" class="table-of-contents__link toc-highlight">Version Management</a></li><li><a href="#custom-model-deployment" class="table-of-contents__link toc-highlight">Custom Model Deployment</a></li><li><a href="#configuration-options" class="table-of-contents__link toc-highlight">Configuration Options</a></li></ul></li><li><a href="#troubleshooting" class="table-of-contents__link toc-highlight">Troubleshooting</a><ul><li><a href="#common-issues" class="table-of-contents__link toc-highlight">Common Issues</a></li><li><a href="#debug-commands" class="table-of-contents__link toc-highlight">Debug Commands</a></li></ul></li><li><a href="#node-selection-and-customization" class="table-of-contents__link toc-highlight">Node Selection and Customization</a><ul><li><a href="#selecting-instance-types" class="table-of-contents__link toc-highlight">Selecting Instance Types</a></li><li><a href="#custom-development" class="table-of-contents__link toc-highlight">Custom Development</a></li></ul></li><li><a href="#multi-node-tensor-parallelism-limitations" class="table-of-contents__link toc-highlight">Multi-Node Tensor Parallelism Limitations</a><ul><li><a href="#understanding-multi-replica-vs-multi-node" class="table-of-contents__link toc-highlight">Understanding Multi-Replica vs Multi-Node</a></li><li><a href="#current-kubernetes-limitations" class="table-of-contents__link toc-highlight">Current Kubernetes Limitations</a></li><li><a href="#current-support-in-dynamo-backends" class="table-of-contents__link toc-highlight">Current Support in Dynamo Backends</a></li><li><a href="#workarounds-for-large-models" class="table-of-contents__link toc-highlight">Workarounds for Large Models</a></li><li><a href="#future-development" class="table-of-contents__link toc-highlight">Future Development</a></li><li><a href="#recommendations" class="table-of-contents__link toc-highlight">Recommendations</a></li></ul></li><li><a href="#alternative-deployment-options" class="table-of-contents__link toc-highlight">Alternative Deployment Options</a><ul><li><a href="#for-existing-eks-clusters" class="table-of-contents__link toc-highlight">For Existing EKS Clusters</a></li><li><a href="#why-use-this-blueprint" class="table-of-contents__link toc-highlight">Why Use This Blueprint?</a></li></ul></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a><ul><li><a href="#official-nvidia-resources" class="table-of-contents__link toc-highlight">Official NVIDIA Resources</a></li><li><a href="#ai-on-eks-blueprint-resources" class="table-of-contents__link toc-highlight">AI-on-EKS Blueprint Resources</a></li><li><a href="#related-technologies" class="table-of-contents__link toc-highlight">Related Technologies</a></li></ul></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li><li><a href="#clean-up" class="table-of-contents__link toc-highlight">Clean Up</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>