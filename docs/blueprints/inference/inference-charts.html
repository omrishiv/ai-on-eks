<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blueprints/inference/inference-charts" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">AI on EKS Inference Charts | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/inference-charts"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="AI on EKS Inference Charts | AI on EKS"><meta data-rh="true" name="description" content="The AI on EKS Inference Charts provide a streamlined Helm-based approach to deploy AI/ML inference workloads on both GPU and AWS Neuron (Inferentia/Trainium) hardware. This chart supports multiple deployment configurations and comes with pre-configured values for popular models."><meta data-rh="true" property="og:description" content="The AI on EKS Inference Charts provide a streamlined Helm-based approach to deploy AI/ML inference workloads on both GPU and AWS Neuron (Inferentia/Trainium) hardware. This chart supports multiple deployment configurations and comes with pre-configured values for popular models."><link data-rh="true" rel="icon" href="/ai-on-eks/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/inference-charts"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/inference-charts" hreflang="en"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/inference-charts" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Inference on EKS","item":"https://awslabs.github.io/ai-on-eks/docs/category/inference-on-eks"},{"@type":"ListItem","position":2,"name":"Inference Charts","item":"https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/inference-charts"}]}</script><link rel="stylesheet" href="/ai-on-eks/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/assets/js/runtime~main.612566b1.js" defer="defer"></script>
<script src="/ai-on-eks/assets/js/main.9a602c3f.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now →</a></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/"><div class="navbar__logo"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/infra">Infrastructure</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/docs/blueprints">Blueprints</a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/guidance">Guidance</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/blueprints"><span title="Overview" class="linkLabel_WmDU">Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/docs/category/training-on-eks"><span title="Training on EKS" class="categoryLinkLabel_W154">Training on EKS</span></a><button aria-label="Expand sidebar category &#x27;Training on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai-on-eks/docs/category/inference-on-eks"><span title="Inference on EKS" class="categoryLinkLabel_W154">Inference on EKS</span></a><button aria-label="Collapse sidebar category &#x27;Inference on EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai-on-eks/docs/category/gpu-inference-on-eks"><span title="GPU Inference on EKS" class="categoryLinkLabel_W154">GPU Inference on EKS</span></a><button aria-label="Expand sidebar category &#x27;GPU Inference on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai-on-eks/docs/category/neuron-inference-on-eks"><span title="Neuron Inference on EKS" class="categoryLinkLabel_W154">Neuron Inference on EKS</span></a><button aria-label="Expand sidebar category &#x27;Neuron Inference on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference"><span title="Overview" class="linkLabel_WmDU">Overview</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/inference-charts"><span title="Inference Charts" class="linkLabel_WmDU">Inference Charts</span></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai-on-eks/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/docs/category/inference-on-eks"><span>Inference on EKS</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Inference Charts</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>AI on EKS Inference Charts</h1></header>
<p>The AI on EKS Inference Charts provide a streamlined Helm-based approach to deploy AI/ML inference workloads on both GPU and AWS Neuron (Inferentia/Trainium) hardware. This chart supports multiple deployment configurations and comes with pre-configured values for popular models.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Advanced Usage</div><div class="admonitionContent_BuS1"><p>For detailed configuration options, advanced deployment scenarios, and comprehensive parameter documentation, see the <a href="https://github.com/awslabs/ai-on-eks/blob/main/blueprints/inference/inference-charts/README.md" target="_blank" rel="noopener noreferrer">complete README</a>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">​</a></h2>
<p>The inference charts support multiple deployment frameworks:</p>
<ul>
<li><strong>VLLM</strong> - Single-node inference with fast startup</li>
<li><strong>Ray-VLLM</strong> - Distributed inference with autoscaling capabilities</li>
<li><strong>Triton-VLLM</strong> - Production-ready inference server with advanced features</li>
<li><strong>AIBrix</strong> - VLLM with AIBrix-specific configurations</li>
<li><strong>LeaderWorkerSet-VLLM</strong> - Multi-node inference for large models</li>
<li><strong>Diffusers</strong> - Hugging Face Diffusers for image generation</li>
</ul>
<p>Both GPU and AWS Neuron (Inferentia/Trainium) accelerators are supported across these frameworks.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h2>
<p>Before deploying the inference charts, ensure you have:</p>
<ul>
<li>Amazon EKS cluster with GPU or AWS Neuron
nodes (<a href="/ai-on-eks/docs/infra/inference-ready-cluster">inference-ready cluster</a> for a quick start)</li>
<li>Helm 3.0+</li>
<li>For GPU deployments: NVIDIA device plugin installed</li>
<li>For Neuron deployments: AWS Neuron device plugin installed</li>
<li>For LeaderWorkerSet deployments: LeaderWorkerSet CRD installed</li>
<li>Hugging Face Hub token (stored as a Kubernetes secret named <code>hf-token</code>)</li>
<li>For Ray: KubeRay Infrastructure</li>
<li>For AIBrix: AIBrix Infrastructure</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="quick-start">Quick Start<a href="#quick-start" class="hash-link" aria-label="Direct link to Quick Start" title="Direct link to Quick Start" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-create-hugging-face-token-secret">1. Create Hugging Face Token Secret<a href="#1-create-hugging-face-token-secret" class="hash-link" aria-label="Direct link to 1. Create Hugging Face Token Secret" title="Direct link to 1. Create Hugging Face Token Secret" translate="no">​</a></h3>
<p>Create a Kubernetes secret with your <a href="https://huggingface.co/docs/hub/en/security-tokens" target="_blank" rel="noopener noreferrer">Hugging Face token</a>:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create secret generic hf-token --from-literal</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">token</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">your_huggingface_token</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-deploy-a-pre-configured-model">2. Deploy a Pre-configured Model<a href="#2-deploy-a-pre-configured-model" class="hash-link" aria-label="Direct link to 2. Deploy a Pre-configured Model" title="Direct link to 2. Deploy a Pre-configured Model" translate="no">​</a></h3>
<p>Choose from the available pre-configured models and deploy:</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>These deployments will need GPU/Neuron resources which need to
be <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-resource-limits.html" target="_blank" rel="noopener noreferrer">enabled</a> and cost more than CPU only
instances.</p></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Deploy Llama 3.2 1B on GPU with vLLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> llama-inference ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-llama-32-1b-vllm.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Deploy DeepSeek R1 Distill on GPU with Ray-vLLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> deepseek-inference ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-deepseek-r1-distill-llama-8b-ray-vllm-gpu.yaml</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="supported-models">Supported Models<a href="#supported-models" class="hash-link" aria-label="Direct link to Supported Models" title="Direct link to Supported Models" translate="no">​</a></h2>
<p>The inference charts include pre-configured values files for popular models across different categories:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="language-models">Language Models<a href="#language-models" class="hash-link" aria-label="Direct link to Language Models" title="Direct link to Language Models" translate="no">​</a></h3>
<ul>
<li><strong>DeepSeek R1 Distill Llama 8B</strong> - Advanced reasoning model</li>
<li><strong>Llama 3.2 1B</strong> - Lightweight language model</li>
<li><strong>Llama 4 Scout 17B</strong> - Mid-size language model</li>
<li><strong>Mistral Small 24B</strong> - Efficient large language model</li>
<li><strong>GPT OSS 20B</strong> - Open-source GPT variant</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="diffusion-models">Diffusion Models<a href="#diffusion-models" class="hash-link" aria-label="Direct link to Diffusion Models" title="Direct link to Diffusion Models" translate="no">​</a></h3>
<ul>
<li><strong>FLUX.1 Schnell</strong> - Fast text-to-image generation</li>
<li><strong>Stable Diffusion XL</strong> - High-quality image generation</li>
<li><strong>Stable Diffusion 3.5</strong> - Latest SD model with enhanced capabilities</li>
<li><strong>Kolors</strong> - Artistic image generation</li>
<li><strong>OmniGen</strong> - Multi-modal generation</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="neuron-optimized-models">Neuron-Optimized Models<a href="#neuron-optimized-models" class="hash-link" aria-label="Direct link to Neuron-Optimized Models" title="Direct link to Neuron-Optimized Models" translate="no">​</a></h3>
<ul>
<li><strong>Llama 2 13B</strong> - Optimized for AWS Inferentia</li>
<li><strong>Llama 3 70B</strong> - Large model on Inferentia</li>
<li><strong>Llama 3.1 8B</strong> - Efficient Inferentia deployment</li>
</ul>
<p>Each model comes with optimized configurations for different frameworks (VLLM, Ray-VLLM, Triton-VLLM, etc.).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployment-examples">Deployment Examples<a href="#deployment-examples" class="hash-link" aria-label="Direct link to Deployment Examples" title="Direct link to Deployment Examples" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="language-model-deployments">Language Model Deployments<a href="#language-model-deployments" class="hash-link" aria-label="Direct link to Language Model Deployments" title="Direct link to Language Model Deployments" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Deploy Llama 3.2 1B with VLLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> llama32-vllm ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-llama-32-1b-vllm.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Deploy DeepSeek R1 Distill with Ray-VLLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> deepseek-ray ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-deepseek-r1-distill-llama-8b-ray-vllm-gpu.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Deploy Llama 4 Scout 17B with LeaderWorkerSet-VLLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> llama4-lws ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-llama-4-scout-17b-lws-vllm.yaml</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="diffusion-model-deployments">Diffusion Model Deployments<a href="#diffusion-model-deployments" class="hash-link" aria-label="Direct link to Diffusion Model Deployments" title="Direct link to Diffusion Model Deployments" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Deploy FLUX.1 Schnell for image generation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> flux-diffusers ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-flux-1-diffusers.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Deploy Stable Diffusion XL</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> sdxl-diffusers ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-stable-diffusion-xl-base-1-diffusers.yaml</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="neuron-deployments">Neuron Deployments<a href="#neuron-deployments" class="hash-link" aria-label="Direct link to Neuron Deployments" title="Direct link to Neuron Deployments" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Deploy Llama 3.1 8B on Inferentia</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> llama31-neuron ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-llama-31-8b-vllm-neuron.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Deploy Llama 3 70B with Ray-VLLM on Inferentia</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> llama3-70b-neuron ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> ./blueprints/inference/inference-charts/values-llama-3-70b-ray-vllm-neuron.yaml</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="configuration">Configuration<a href="#configuration" class="hash-link" aria-label="Direct link to Configuration" title="Direct link to Configuration" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-parameters">Key Parameters<a href="#key-parameters" class="hash-link" aria-label="Direct link to Key Parameters" title="Direct link to Key Parameters" translate="no">​</a></h3>
<table><thead><tr><th>Parameter</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>inference.accelerator</code></td><td>Accelerator type (<code>gpu</code> or <code>neuron</code>)</td><td><code>gpu</code></td></tr><tr><td><code>inference.framework</code></td><td>Framework (<code>vllm</code>, <code>ray-vllm</code>, <code>triton-vllm</code>, <code>aibrix</code>, etc.)</td><td><code>vllm</code></td></tr><tr><td><code>inference.serviceName</code></td><td>Name of the inference service</td><td><code>inference</code></td></tr><tr><td><code>inference.modelServer.deployment.replicas</code></td><td>Number of replicas</td><td><code>1</code></td></tr><tr><td><code>model</code></td><td>Model ID from Hugging Face Hub</td><td><code>NousResearch/Llama-3.2-1B</code></td></tr><tr><td><code>modelParameters.gpuMemoryUtilization</code></td><td>GPU memory utilization</td><td><code>0.8</code></td></tr><tr><td><code>modelParameters.maxModelLen</code></td><td>Maximum model sequence length</td><td><code>8192</code></td></tr><tr><td><code>modelParameters.tensorParallelSize</code></td><td>Tensor parallel size</td><td><code>1</code></td></tr><tr><td><code>modelParameters.pipelineParallelSize</code></td><td>Pipeline parallel size</td><td><code>1</code></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="custom-configuration">Custom Configuration<a href="#custom-configuration" class="hash-link" aria-label="Direct link to Custom Configuration" title="Direct link to Custom Configuration" translate="no">​</a></h3>
<p>Create a custom values file:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">inference</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">accelerator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu  </span><span class="token comment" style="color:#999988;font-style:italic"># or neuron</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">framework</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> vllm   </span><span class="token comment" style="color:#999988;font-style:italic"># vllm, ray-vllm, triton-vllm, aibrix, lws-vllm, diffusers</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">serviceName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> my</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">modelServer</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">deployment</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">replicas</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">instanceType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g5.2xlarge</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;NousResearch/Llama-3.2-1B&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">modelParameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">gpuMemoryUtilization</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">maxModelLen</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8192</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tensorParallelSize</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><br></span></code></pre></div></div>
<p>Deploy with custom values:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> my-inference ./blueprints/inference/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> custom-values.yaml</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="api-usage">API Usage<a href="#api-usage" class="hash-link" aria-label="Direct link to API Usage" title="Direct link to API Usage" translate="no">​</a></h2>
<p>The deployed services expose different API endpoints based on the framework:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vllmray-vllm">VLLM/Ray-VLLM<a href="#vllmray-vllm" class="hash-link" aria-label="Direct link to VLLM/Ray-VLLM" title="Direct link to VLLM/Ray-VLLM" translate="no">​</a></h3>
<ul>
<li><code>/v1/models</code> - List available models</li>
<li><code>/v1/chat/completions</code> - Chat completion API</li>
<li><code>/v1/completions</code> - Text completion API</li>
<li><code>/metrics</code> - Prometheus metrics</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="triton-vllm">Triton-VLLM<a href="#triton-vllm" class="hash-link" aria-label="Direct link to Triton-VLLM" title="Direct link to Triton-VLLM" translate="no">​</a></h3>
<ul>
<li><code>/v2/models</code> - List available models</li>
<li><code>/v2/models/vllm_model/generate</code> - Model inference</li>
<li><code>/v2/health/ready</code> - Health checks</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="diffusers">Diffusers<a href="#diffusers" class="hash-link" aria-label="Direct link to Diffusers" title="Direct link to Diffusers" translate="no">​</a></h3>
<ul>
<li><code>/v1/generations</code> - Image generation API</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-usage">Example Usage<a href="#example-usage" class="hash-link" aria-label="Direct link to Example Usage" title="Direct link to Example Usage" translate="no">​</a></h3>
<p>Access your service via port-forward:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">service-name</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8000</span><br></span></code></pre></div></div>
<p>Test the API:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Chat completion (VLLM/Ray-VLLM)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://localhost:8000/v1/chat/completions </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;model&quot;: &quot;your-model-name&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}],</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;max_tokens&quot;: 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">  }&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Image generation (Diffusers)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://localhost:8000/v1/generations </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;Content-Type: application/json&#x27;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{&quot;prompt&quot;: &quot;A beautiful sunset over mountains&quot;}&#x27;</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="troubleshooting">Troubleshooting<a href="#troubleshooting" class="hash-link" aria-label="Direct link to Troubleshooting" title="Direct link to Troubleshooting" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="common-issues">Common Issues<a href="#common-issues" class="hash-link" aria-label="Direct link to Common Issues" title="Direct link to Common Issues" translate="no">​</a></h3>
<ol>
<li>
<p><strong>Pod stuck in Pending state</strong></p>
<ul>
<li>Check if GPU/Neuron nodes are available</li>
<li>Verify resource requests match available hardware</li>
<li>For LeaderWorkerSet deployments: Ensure LeaderWorkerSet CRD is installed</li>
</ul>
</li>
<li>
<p><strong>Model download failures</strong></p>
<ul>
<li>Ensure Hugging Face token is correctly configured as secret <code>hf-token</code></li>
<li>Check network connectivity to Hugging Face Hub</li>
<li>Verify model ID is correct and accessible</li>
</ul>
</li>
<li>
<p><strong>Out of memory errors</strong></p>
<ul>
<li>Adjust <code>gpuMemoryUtilization</code> parameter (try reducing from 0.8 to 0.7)</li>
<li>Consider using tensor parallelism for larger models</li>
<li>For large models, use LeaderWorkerSet or Ray deployments with multiple GPUs</li>
</ul>
</li>
<li>
<p><strong>Ray deployment issues</strong></p>
<ul>
<li>Ensure KubeRay infrastructure is installed</li>
<li>Check Ray cluster status and worker connectivity</li>
<li>Verify Ray version compatibility</li>
</ul>
</li>
<li>
<p><strong>Triton deployment issues</strong></p>
<ul>
<li>Check Triton server logs for model loading errors</li>
<li>Verify model repository configuration</li>
<li>Ensure proper health check endpoints are accessible</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logs">Logs<a href="#logs" class="hash-link" aria-label="Direct link to Logs" title="Direct link to Logs" translate="no">​</a></h3>
<p>Check deployment logs based on framework:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="check-logs">Check Logs<a href="#check-logs" class="hash-link" aria-label="Direct link to Check Logs" title="Direct link to Check Logs" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># VLLM deployments</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> app.kubernetes.io/component</span><span class="token operator" style="color:#393A34">=</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">service-name</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Ray deployments</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> ray.io/node-type</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">head</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> ray.io/node-type</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">worker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># LeaderWorkerSet deployments</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> leaderworkerset.sigs.k8s.io/role</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">leader</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">​</a></h2>
<ul>
<li>Explore <a href="/ai-on-eks/docs/category/gpu-inference-on-eks">GPU-specific configurations</a> for GPU deployments</li>
<li>Learn about <a href="/ai-on-eks/docs/category/neuron-inference-on-eks">Neuron-specific configurations</a> for Inferentia deployments</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/inference/inference-charts.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/docs/blueprints/inference"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Overview</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#quick-start" class="table-of-contents__link toc-highlight">Quick Start</a><ul><li><a href="#1-create-hugging-face-token-secret" class="table-of-contents__link toc-highlight">1. Create Hugging Face Token Secret</a></li><li><a href="#2-deploy-a-pre-configured-model" class="table-of-contents__link toc-highlight">2. Deploy a Pre-configured Model</a></li></ul></li><li><a href="#supported-models" class="table-of-contents__link toc-highlight">Supported Models</a><ul><li><a href="#language-models" class="table-of-contents__link toc-highlight">Language Models</a></li><li><a href="#diffusion-models" class="table-of-contents__link toc-highlight">Diffusion Models</a></li><li><a href="#neuron-optimized-models" class="table-of-contents__link toc-highlight">Neuron-Optimized Models</a></li></ul></li><li><a href="#deployment-examples" class="table-of-contents__link toc-highlight">Deployment Examples</a><ul><li><a href="#language-model-deployments" class="table-of-contents__link toc-highlight">Language Model Deployments</a></li><li><a href="#diffusion-model-deployments" class="table-of-contents__link toc-highlight">Diffusion Model Deployments</a></li><li><a href="#neuron-deployments" class="table-of-contents__link toc-highlight">Neuron Deployments</a></li></ul></li><li><a href="#configuration" class="table-of-contents__link toc-highlight">Configuration</a><ul><li><a href="#key-parameters" class="table-of-contents__link toc-highlight">Key Parameters</a></li><li><a href="#custom-configuration" class="table-of-contents__link toc-highlight">Custom Configuration</a></li></ul></li><li><a href="#api-usage" class="table-of-contents__link toc-highlight">API Usage</a><ul><li><a href="#vllmray-vllm" class="table-of-contents__link toc-highlight">VLLM/Ray-VLLM</a></li><li><a href="#triton-vllm" class="table-of-contents__link toc-highlight">Triton-VLLM</a></li><li><a href="#diffusers" class="table-of-contents__link toc-highlight">Diffusers</a></li><li><a href="#example-usage" class="table-of-contents__link toc-highlight">Example Usage</a></li></ul></li><li><a href="#troubleshooting" class="table-of-contents__link toc-highlight">Troubleshooting</a><ul><li><a href="#common-issues" class="table-of-contents__link toc-highlight">Common Issues</a></li><li><a href="#logs" class="table-of-contents__link toc-highlight">Logs</a></li><li><a href="#check-logs" class="table-of-contents__link toc-highlight">Check Logs</a></li></ul></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>